{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    columns = y_true.shape[1]\n",
    "    column_losses = []\n",
    "    for i in range(0, columns):\n",
    "        column_losses.append(log_loss(y_true[:, i], y_pred[:, i]))\n",
    "    return np.array(column_losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_names = ['val1.csv', 'val2.csv', '415_val.csv', '250_val.csv', 'p100_val.csv', 'p100_val2.csv', '200_gru_val.csv', '2801_val.csv', 'final_val.csv', 'final2_val.csv']\n",
    "test_names = ['test1.csv', 'test2.csv', '415_test.csv', '250_test.csv', 'p100_test.csv', 'p100_test2.csv', '200_gru_test.csv', '2801_test.csv', 'final_test.csv', 'final2_test.csv']\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "ground_truth = pd.read_csv(\"../train.csv\")\n",
    "y = ground_truth[list_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "for j in range(len(validation_names)):\n",
    "    train.append(pd.read_csv(validation_names[j]))\n",
    "    test.append(pd.read_csv(test_names[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model: toxic\n",
      "Working on model: severe_toxic\n",
      "Working on model: obscene\n",
      "Working on model: threat\n",
      "Working on model: insult\n",
      "Working on model: identity_hate\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression Stacker- replaced with following minimization routine\n",
    "val_preds = {}\n",
    "test_preds= {}\n",
    "for i, category in enumerate(list_classes):\n",
    "    print(\"Working on model: {:s}\".format(category))\n",
    "    X_train = np.column_stack([mdl[category].values for mdl in train])\n",
    "    X_test = np.column_stack([mdl[category].values for mdl in test])\n",
    "    valpred = np.zeros(y.shape[0])\n",
    "    testpred = np.zeros(test[0][list_classes].values.shape[0])\n",
    "    clf = linear_model.LinearRegression(n_jobs=-1)\n",
    "    clf.fit(X_train, y[:,i])\n",
    "    valpred = clf.predict(X_train) #Not training any hyperparameters, just fit on everything\n",
    "    testpred =  clf.predict(X_test)\n",
    "    test_preds[category]=testpred\n",
    "    val_preds[category]= valpred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def function_metric(x,label, train_index):\n",
    "    x = [max(val, 0) for val in x]\n",
    "    x = x / np.array(x).sum()\n",
    "    y_test = np.zeros(len(train_index))\n",
    "    for k in range(len(validation_names)):\n",
    "        y_test += x[k]*train[k][list_classes[label]].values[train_index]\n",
    "    logloss = log_loss(y[train_index,label], y_test)\n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model: toxic\n",
      "Fitting fold 0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.083133\n",
      "         Iterations: 350\n",
      "         Function evaluations: 507\n",
      "Fitting fold 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.084477\n",
      "         Iterations: 463\n",
      "         Function evaluations: 666\n",
      "Fitting fold 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.085127\n",
      "         Iterations: 495\n",
      "         Function evaluations: 708\n",
      "Working on model: severe_toxic\n",
      "Fitting fold 0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022179\n",
      "         Iterations: 479\n",
      "         Function evaluations: 685\n",
      "Fitting fold 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021861\n",
      "         Iterations: 499\n",
      "         Function evaluations: 739\n",
      "Fitting fold 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021698\n",
      "         Iterations: 503\n",
      "         Function evaluations: 720\n",
      "Working on model: obscene\n",
      "Fitting fold 0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.044894\n",
      "         Iterations: 490\n",
      "         Function evaluations: 689\n",
      "Fitting fold 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.042642\n",
      "         Iterations: 353\n",
      "         Function evaluations: 517\n",
      "Fitting fold 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.043881\n",
      "         Iterations: 432\n",
      "         Function evaluations: 623\n",
      "Working on model: threat\n",
      "Fitting fold 0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.007731\n",
      "         Iterations: 518\n",
      "         Function evaluations: 732\n",
      "Fitting fold 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.008729\n",
      "         Iterations: 437\n",
      "         Function evaluations: 625\n",
      "Fitting fold 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.007676\n",
      "         Iterations: 482\n",
      "         Function evaluations: 694\n",
      "Working on model: insult\n",
      "Fitting fold 0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.057865\n",
      "         Iterations: 404\n",
      "         Function evaluations: 585\n",
      "Fitting fold 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.056382\n",
      "         Iterations: 574\n",
      "         Function evaluations: 823\n",
      "Fitting fold 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.055719\n",
      "         Iterations: 491\n",
      "         Function evaluations: 705\n",
      "Working on model: identity_hate\n",
      "Fitting fold 0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018631\n",
      "         Iterations: 600\n",
      "         Function evaluations: 871\n",
      "Fitting fold 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018926\n",
      "         Iterations: 431\n",
      "         Function evaluations: 636\n",
      "Fitting fold 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017736\n",
      "         Iterations: 378\n",
      "         Function evaluations: 555\n"
     ]
    }
   ],
   "source": [
    "num_folds = 3\n",
    "num_models = len(validation_names)\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "x0 = np.array([1 for _ in range(num_models)])\n",
    "val_preds = {}\n",
    "test_preds= {}\n",
    "for i, category in enumerate(list_classes):\n",
    "    print(\"Working on model: {:s}\".format(category))\n",
    "    valpred = np.zeros(y.shape[0])\n",
    "    testpred = np.zeros(test[0][list_classes].values.shape[0])\n",
    "    for j, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        print(\"Fitting fold {:d}\".format(j))\n",
    "        res = minimize(function_metric, x0, args=(i, train_index), method='nelder-mead', options={'xtol': 1e-3, 'disp': True})\n",
    "        coeffs = [max(val, 0) for val in res.x]\n",
    "        x_res = coeffs / np.array(coeffs).sum()    \n",
    "        prediction = np.zeros(len(test_index))\n",
    "        \n",
    "        for k in range(num_models):\n",
    "            prediction += x_res[k]*train[k][category].values[test_index]  \n",
    "            \n",
    "        test_prediction = np.zeros(X_test.shape[0])\n",
    "        for k in range(num_models):\n",
    "            test_prediction += x_res[k]*test[k][category].values   \n",
    "            \n",
    "        valpred[test_index] = prediction\n",
    "        testpred+=test_prediction\n",
    "    testpred = testpred/num_folds\n",
    "    test_preds[category]=testpred\n",
    "    val_preds[category]= valpred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038969271214682986"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valpred = np.column_stack([val_preds[category] for category in list_classes])\n",
    "testpred = np.column_stack([test_preds[category] for category in list_classes])\n",
    "metric(y,valpred.clip(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../sample_submission.csv\")\n",
    "sample_submission[list_classes] = testpred.clip(0,1)\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
