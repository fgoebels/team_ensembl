{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "9f98d6d8-91b9-4a29-b0fd-1d4dc6d44b56",
    "_uuid": "51e273969e987caf0309f1e8d864150ca30028d9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "bb36cfbf-8927-4802-b4e0-30f17495c013",
    "_uuid": "719260666561e8b10860356e148dbe93d90a6d64",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_cleaned.csv')\n",
    "test = pd.read_csv('./test_cleaned.csv')\n",
    "X_train = train['comment_text'].fillna(\"CVxTz\").values\n",
    "X_test = test['comment_text'].fillna(\"CVxTz\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    columns = y_true.shape[1]\n",
    "    column_losses = []\n",
    "    for i in range(0, columns):\n",
    "        column_losses.append(log_loss(y_true[:, i], y_pred[:, i]))\n",
    "    return np.array(column_losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(analyzer='char', ngram_range=(1,4), max_features=50000, min_df=2)\n",
    "print(\"Vectorizing\")\n",
    "vect.fit(X_train)\n",
    "X_test_dm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectoring fold 2\n",
      "Vectoring fold 4\n",
      "Vectoring fold 5\n",
      "Vectoring fold 9\n",
      "Vectoring fold 8\n",
      "Vectoring fold 7\n",
      "Vectoring fold 6\n",
      "Vectoring fold 3\n",
      "Vectoring fold 0\n",
      "Vectoring fold 1\n"
     ]
    }
   ],
   "source": [
    "mysplits = pd.read_csv('./splits.csv')\n",
    "num_folds = mysplits['split'].unique().shape[0]\n",
    "\n",
    "X_train_dm = {}\n",
    "X_val_dm = {}\n",
    "#Pre-processing for fitting, memory intensive\n",
    "for j in mysplits['split'].unique():\n",
    "    print(\"Vectoring fold {:d}\".format(j))\n",
    "    test_index = mysplits.index[mysplits['split']==j]\n",
    "    train_index = mysplits.index[mysplits['split']!=j]\n",
    "    X_train_dm[j]= vect.transform(X_train[train_index])\n",
    "    X_val_dm[j] = vect.transform(X_train[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model: toxic\n",
      "Working on model: severe_toxic\n",
      "Working on model: obscene\n",
      "Working on model: threat\n",
      "Working on model: insult\n",
      "Working on model: identity_hate\n"
     ]
    }
   ],
   "source": [
    "val_preds = {}\n",
    "test_preds= {}\n",
    "for i, category in enumerate(list_classes):\n",
    "    print(\"Working on model: {:s}\".format(category))\n",
    "    valpred = np.zeros(y.shape[0])\n",
    "    testpred = np.zeros(test.shape[0])\n",
    "    for j in mysplits['split'].unique():\n",
    "        test_index = mysplits.index[mysplits['split']==j]\n",
    "        train_index = mysplits.index[mysplits['split']!=j]\n",
    "        #print(\"Fitting fold {:d}\".format(j))\n",
    "        \n",
    "        clf = LogisticRegression(C=9.0, n_jobs=-1)\n",
    "        clf.fit(X_train_dm[j], y[train_index,i])       \n",
    "        prediction = clf.predict_proba(X_val_dm[j])[:,1]\n",
    "        valpred[test_index] = prediction\n",
    "        test_prediction =  clf.predict_proba(X_test_dm)[:,1]\n",
    "        testpred+=test_prediction\n",
    "    testpred = testpred/num_folds\n",
    "    test_preds[category]=testpred\n",
    "    val_preds[category]= valpred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050380818262615416"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valpred = np.column_stack([val_preds[category] for category in list_classes])\n",
    "testpred = np.column_stack([test_preds[category] for category in list_classes])\n",
    "metric(y,valpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "sample_submission[list_classes] = testpred.clip(0,1)\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"./train.csv\")\n",
    "temp[list_classes] = valpred\n",
    "temp.to_csv(\"validation_predictions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
