{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 17)\n",
      "(159571, 24)\n",
      "(159571, 31)\n",
      "(159571, 38)\n",
      "(159571, 45)\n",
      "(159571, 52)\n",
      "(159571, 58)\n",
      "(159571, 62)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./train_cleaned_unfiltered.csv\")\n",
    "list_classes = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train = train[list_classes]\n",
    "\n",
    "train_files = [\"out/train_1703_FG_LDA.csv\", \n",
    "               \"out/train_1703_FG_lstm_combined.csv\", \n",
    "               \"out/train_1703_FG_nb_lr_combined.csv\",\n",
    "               \"out/train_1703_FG_nn_combined.csv\",\n",
    "               \"out/train_1703_FG_rnd_forest_combined.csv\",\n",
    "               \"out/train_1703_FG_xgboost_combined.csv\",\n",
    "               \"out/train_1803_FG_LSTMmulticlass.csv\",\n",
    "               \"out/train_1803_FG_vader.csv\"\n",
    "              ]\n",
    "\n",
    "for f in train_files:\n",
    "    table =  pd.read_csv(f, header=None)\n",
    "    table.rename(columns={0:'id'}, inplace=True)\n",
    "    train = pd.merge(train, table, on = [\"id\"])\n",
    "    print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 11)\n",
      "(153164, 18)\n",
      "(153164, 25)\n",
      "(153164, 32)\n",
      "(153164, 39)\n",
      "(153164, 46)\n",
      "(153164, 52)\n",
      "(153164, 56)\n",
      "(153164, 62)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"./test_cleaned_unfiltered.csv\")\n",
    "list_classes = [\"id\"]\n",
    "test = test[list_classes]\n",
    "\n",
    "test_files =  [\"out/test_1703_FG_LDA.csv\", \n",
    "               \"out/test_1703_FG_lstm_combined.csv\", \n",
    "               \"out/test_1703_FG_nb_lr_combined.csv\",\n",
    "               \"out/test_1703_FG_nn_combined.csv\",\n",
    "               \"out/test_1703_FG_rnd_forest_combined.csv\",\n",
    "               \"out/test_1703_FG_xgboost_combined.csv\",\n",
    "               \"out/test_1803_FG_LSTMmulticlass.csv\",\n",
    "               \"out/test_1803_FG_vader.csv\",\n",
    "               \"out/test_kevin.csv\"\n",
    "              ]\n",
    "\n",
    "for f in test_files:\n",
    "    table =  pd.read_csv(f, header=None)\n",
    "    table.rename(columns={0:'id'}, inplace=True)\n",
    "    test = pd.merge(test, table, on = [\"id\"])\n",
    "    print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_classes = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "X = train.drop(list_classes, axis= 1 ).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp =  pd.read_csv(\"out/train_kevin.csv\")\n",
    "X_train_kevin = tmp.values\n",
    "X = np.column_stack([X, X_train_kevin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 61)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class LR:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "\n",
    "    def get_mdl(self, X, y):\n",
    "        m = LogisticRegression(C=10, dual=True)\n",
    "        return m.fit(X, y)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if len(y.shape)>1:\n",
    "            for i in range(y.shape[1]):\n",
    "                m = self.get_mdl(X, y[:,i])\n",
    "                self.models.append((m))\n",
    "        else:\n",
    "            m = self.get_mdl(X, y)\n",
    "            self.models.append((m))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        preds = np.zeros((X.shape[0], len(self.models)))\n",
    "        for i in range(len(self.models)):\n",
    "            m = self.models[i]\n",
    "            preds[:,i] = m.predict_proba(X)[:,1]\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106912, 55)\n",
      "(52659, 55)\n",
      "(106912, 6)\n",
      "(52659, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "for tbl in [X_train, X_val, y_train, y_val]:\n",
    "    print tbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999851332423976\n"
     ]
    }
   ],
   "source": [
    "l = LogisticRegression(C=10, dual=True)\n",
    "lr = LR()\n",
    "lr.fit(X, y)\n",
    "pred = lr.predict(X)\n",
    "print(roc_auc_score(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = test.drop([\"id\"], axis= 1 ).values\n",
    "to_predict.shape\n",
    "y_pred = lr.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999873282424735\n"
     ]
    }
   ],
   "source": [
    "l = LogisticRegression(C=10, dual=True)\n",
    "lr = LR()\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_val)\n",
    "print(roc_auc_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "submid = pd.DataFrame({'id': test[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(y_pred, columns = list_classes)], axis=1)\n",
    "print(submission.shape)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from  keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class nn_1vsall_clf:\n",
    "    \n",
    "        \n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "    \n",
    "    def get_mdl(self, X, y):\n",
    "        adam = Adam(lr=0.001)\n",
    "        model = Sequential()\n",
    "        model.add(BatchNormalization(input_shape=(X.shape[1],)))\n",
    "        model.add(Dense(2048, activation='sigmoid'))\n",
    "        model.add(Dropout(rate=0.6))\n",
    "        model.add(Dense(2048, activation='sigmoid'))\n",
    "        model.add(Dropout(rate=0.6))\n",
    "        #self.model.add(Dense(2048, activation='sigmoid'))\n",
    "        #self.model.add(Dropout(rate=0.6))\n",
    "        #self.model.add(Dense(2048, activation='sigmoid'))\n",
    "        #self.model.add(Dropout(rate=0.6))\n",
    "        if len(y.shape) > 1:\n",
    "            model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "            model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "        else:\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.compile(loss=\"roc_auc_score \", optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "        #print(self.model.summary())\n",
    "        batch_size = 512\n",
    "        model.fit(X, y, batch_size=512, epochs=20)\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if len(y.shape)>1:\n",
    "            for i in range(y.shape[1]):\n",
    "                m = self.get_mdl(X, y[:,i])\n",
    "                self.models.append((m))\n",
    "        else:\n",
    "            m = self.get_mdl(X, y)\n",
    "            self.models.append((m))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        preds = np.zeros((X.shape[0], len(self.models)))\n",
    "        for i in range(len(self.models)):\n",
    "            m = self.models[i]\n",
    "            preds[:,i] = m.predict(X).flatten()\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function:roc_auc_score ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b1210ea8485f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_1vsall_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-bbdee8034bdf>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-bbdee8034bdf>\u001b[0m in \u001b[0;36mget_mdl\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"roc_auc_score \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#print(self.model.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                            \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_function\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/losses.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/losses.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    112\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                                     printable_module_name='loss function')\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 164\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function:roc_auc_score "
     ]
    }
   ],
   "source": [
    "nn = nn_1vsall_clf()\n",
    "nn.fit(X_train, y_train)\n",
    "pred = nn.predict(X_val)\n",
    "print(roc_auc_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 49879  | total loss: \u001b[1m\u001b[32m1.64143\u001b[0m\u001b[0m | time: 14.700s\n",
      "| Adam | epoch: 020 | loss: 1.64143 -- iter: 159552/159571\n",
      "Training Step: 49880  | total loss: \u001b[1m\u001b[32m1.47887\u001b[0m\u001b[0m | time: 14.706s\n",
      "| Adam | epoch: 020 | loss: 1.47887 -- iter: 159571/159571\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Building deep neural network\n",
    "input_layer = tflearn.input_data(shape=[None, 61])\n",
    "dense1 = tflearn.fully_connected(input_layer, 64, activation='tanh',\n",
    "                                 regularizer='L2', weight_decay=0.001)\n",
    "dropout1 = tflearn.dropout(dense1, 0.8)\n",
    "dense2 = tflearn.fully_connected(dropout1, 64, activation='tanh',\n",
    "                                 regularizer='L2', weight_decay=0.001)\n",
    "dropout2 = tflearn.dropout(dense2, 0.8)\n",
    "softmax = tflearn.fully_connected(dropout2, 6, activation='sigmoid')\n",
    "\n",
    "# Regression using SGD with learning rate decay and Top-3 accuracy\n",
    "sgd = tflearn.Adam(learning_rate=0.0001)\n",
    "top_k = tflearn.metrics.Top_k(3)\n",
    "net = tflearn.regression(softmax, optimizer=sgd, metric=top_k,\n",
    "                         loss='roc_auc_score')\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(X, y, n_epoch=20, run_id=\"dense_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = test.drop([\"id\"], axis= 1 ).values\n",
    "to_predict.shape\n",
    "y_pred = model.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 7)\n"
     ]
    }
   ],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "submid = pd.DataFrame({'id': test[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(y_pred, columns = list_classes)], axis=1)\n",
    "print(submission.shape)\n",
    "submission.to_csv('submission-tflearn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from  keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class nn_tf:\n",
    "    \n",
    "        \n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "    \n",
    "    def get_mdl(self, X, y):\n",
    "       # Building deep neural network\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        input_layer = tflearn.input_data(shape=[None, 61])\n",
    "        dense1 = tflearn.fully_connected(input_layer, 256, activation='relu',\n",
    "                                         regularizer='L2', weight_decay=0.001)\n",
    "        dropout1 = tflearn.dropout(dense1, 0.8)\n",
    "        dense2 = tflearn.fully_connected(dropout1, 256, activation='relu',\n",
    "                                         regularizer='L2', weight_decay=0.001)\n",
    "        dropout2 = tflearn.dropout(dense2, 0.8)\n",
    "        softmax = tflearn.fully_connected(dropout2, 1, activation='sigmoid')\n",
    "\n",
    "        # Regression using SGD with learning rate decay and Top-3 accuracy\n",
    "        sgd = tflearn.Adam(learning_rate=0.0001)\n",
    "        top_k = tflearn.metrics.Top_k(3)\n",
    "        net = tflearn.regression(softmax, optimizer=sgd, metric=top_k,\n",
    "                                 loss='roc_auc_score')\n",
    "\n",
    "        # Training\n",
    "        model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "        model.fit(X, y, n_epoch=1, run_id=\"dense_model\")\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if len(y.shape)>1:\n",
    "            for i in range(y.shape[1]):\n",
    "                m = self.get_mdl(X, y[:,1].reshape(y.shape[0],1))\n",
    "                self.models.append((m))\n",
    "        else:\n",
    "            m = self.get_mdl(X, y)\n",
    "            self.models.append((m))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        preds = np.zeros((X.shape[0], len(self.models)))\n",
    "        for i in range(len(self.models)):\n",
    "            m = self.models[i]\n",
    "            preds[:,i] = m.predict(X).flatten()\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,1].reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2493  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 15.514s\n",
      "| Adam | epoch: 001 | loss: 0.00030 -- iter: 159552/159571\n",
      "Training Step: 2494  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 15.519s\n",
      "| Adam | epoch: 001 | loss: 0.00027 -- iter: 159571/159571\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "nn = nn_tf()\n",
    "nn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tflearn.models.dnn.DNN at 0x7f0438e4d850>,\n",
       " <tflearn.models.dnn.DNN at 0x7f0364cc1210>,\n",
       " <tflearn.models.dnn.DNN at 0x7f03642eb890>,\n",
       " <tflearn.models.dnn.DNN at 0x7f035eccc290>,\n",
       " <tflearn.models.dnn.DNN at 0x7f0353b3ca50>,\n",
       " <tflearn.models.dnn.DNN at 0x7f03442fcc50>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 7)\n"
     ]
    }
   ],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "submid = pd.DataFrame({'id': test[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(y_pred, columns = list_classes)], axis=1)\n",
    "print(submission.shape)\n",
    "submission.to_csv('submission-tflearn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
