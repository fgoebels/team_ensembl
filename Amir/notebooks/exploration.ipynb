{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif, SelectPercentile\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = [x for x in train.columns if x not in ['id', 'comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.fillna(' ', inplace=True)\n",
    "train.fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(col):\n",
    "    col = col.str.lower()\n",
    "    col = col.replace(r'\\n', ' ').replace(r'\\t', ' ')\n",
    "    col = col.replace(r'[^a-z\\s]', '', regex=True)\n",
    "    col = col.replace(r'\\s+', ' ', regex=True)\n",
    "    col = col.replace(r\"([a-z]+?)\\1+\", r\"\\1\\1\", regex=True) # removes any repetitions of letters more than twice\n",
    "    col = col.replace(r\"\\b(\\w+)(\\s)(\\1\\2?)+\", r\"\\1\", regex=True) # removes any repetitions of words more than once\n",
    "    col = col.str.strip()\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['comment_text_clean'] = clean_text(train['comment_text'])\n",
    "test['comment_text_clean'] = clean_text(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df, X_val_df, y_train, y_val = train_test_split(train['comment_text_clean'], \n",
    "                                                        train[classes], \n",
    "                                                        test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vectorizer():\n",
    "    def __init__(self, analyzer='both'):\n",
    "        self.analyzer = analyzer\n",
    "        self.vect_words = TfidfVectorizer(max_features=None, \n",
    "                                         analyzer='word', \n",
    "                                         ngram_range=(1, 3), \n",
    "                                         max_df=0.1, \n",
    "                                         min_df=3,\n",
    "                                         stop_words='english',\n",
    "                                         use_idf=True)\n",
    "        self.vect_chars = TfidfVectorizer(max_features=None, \n",
    "                                         analyzer='char', \n",
    "                                         ngram_range=(1, 5), \n",
    "                                         max_df=1., \n",
    "                                         min_df=1,\n",
    "                                         use_idf=True)\n",
    "        \n",
    "    def fit(self, col):\n",
    "        if self.analyzer == 'both':\n",
    "            self.vect_words.fit(col)\n",
    "            self.vect_chars.fit(col)\n",
    "        elif self.analyzer == 'word':\n",
    "            self.vect_words.fit(col)\n",
    "        elif self.analyzer == 'char':\n",
    "            self.vect_chars.fit(col)\n",
    "        else:\n",
    "            print('no valid analyzer chosen')\n",
    "        \n",
    "    def transform(self, col):\n",
    "        if self.analyzer == 'both':\n",
    "            vec = sparse.hstack([self.vect_words.transform(col), \n",
    "                                 self.vect_chars.transform(col)])\n",
    "        elif self.analyzer == 'word':\n",
    "            vec = self.vect_words.transform(col)\n",
    "        elif self.analyzer == 'char':\n",
    "            vec = self.vect_chars.transform(col)\n",
    "        else:\n",
    "            raise Exception('no valid analyzer chosen')\n",
    "            \n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = vectorizer(analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(train['comment_text_clean'].append(test['comment_text_clean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vect.transform(X_train_df)\n",
    "X_val = vect.transform(X_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67095, 607218)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "# the docker container is too small to run the gridsearch\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 10, 'selec__percentile': 3}\n",
      "-0.12636351563\n",
      "Model for toxic trained\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 5, 'selec__percentile': 1}\n",
      "-0.0317368187626\n",
      "Model for severe_toxic trained\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 15, 'selec__percentile': 1}\n",
      "-0.0713910449415\n",
      "Model for obscene trained\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 10, 'selec__percentile': 8}\n",
      "-0.0129166544542\n",
      "Model for threat trained\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 7, 'selec__percentile': 3}\n",
      "-0.0886363386131\n",
      "Model for insult trained\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 7, 'selec__percentile': 1}\n",
      "-0.0284944258322\n",
      "Model for identity_hate trained\n",
      "CPU times: user 1min 27s, sys: 2.82 s, total: 1min 30s\n",
      "Wall time: 25min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = {}\n",
    "feature_selector = {}\n",
    "for toxicity in classes:\n",
    "    selec = SelectPercentile(chi2, \n",
    "                             percentile=20)\n",
    "    clf = LogisticRegression(C=5.0, class_weight=None, n_jobs=1)  \n",
    "    #clf = GradientBoostingClassifier()\n",
    "    pipe = Pipeline(steps=[('selec', selec), \n",
    "                           ('clf', clf)])\n",
    "    parameters = {'selec__percentile':[1, 3, 6, 8], \n",
    "                  'clf__C':[1, 5, 7, 10, 15]}\n",
    "    est = GridSearchCV(pipe, \n",
    "                       parameters, \n",
    "                       scoring='neg_log_loss', \n",
    "                       n_jobs=-1,\n",
    "                       cv=3, \n",
    "                       verbose=1)\n",
    "    est.fit(X_train, y_train[toxicity])\n",
    "    models[toxicity] = est\n",
    "    print(est.best_params_)\n",
    "    print(est.best_score_)\n",
    "    print(\"Model for %s trained\" % toxicity, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "test log-loss: 0.124\n",
      "train log-loss: 0.062\n",
      "test confusion matrix\n",
      "[[25844   157]\n",
      " [ 1131  1624]]\n",
      "severe_toxic\n",
      "test log-loss: 0.03\n",
      "train log-loss: 0.016\n",
      "test confusion matrix\n",
      "[[28429    50]\n",
      " [  245    32]]\n",
      "obscene\n",
      "test log-loss: 0.064\n",
      "train log-loss: 0.037\n",
      "test confusion matrix\n",
      "[[27147    86]\n",
      " [  556   967]]\n",
      "threat\n",
      "test log-loss: 0.013\n",
      "train log-loss: 0.003\n",
      "test confusion matrix\n",
      "[[28657     7]\n",
      " [   82    10]]\n",
      "insult\n",
      "test log-loss: 0.084\n",
      "train log-loss: 0.042\n",
      "test confusion matrix\n",
      "[[27207   156]\n",
      " [  727   666]]\n",
      "identity_hate\n",
      "test log-loss: 0.03\n",
      "train log-loss: 0.011\n",
      "test confusion matrix\n",
      "[[28476    15]\n",
      " [  229    36]]\n",
      "test mean log-loss: 0.0576875404096\n",
      "train mean log-loss: 0.0285301237115\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions_tr = pd.DataFrame()\n",
    "loss = 0\n",
    "loss_tr = 0\n",
    "for toxicity in classes:\n",
    "    predictions[toxicity] = models[toxicity].best_estimator_.predict_proba(X_val)[:, 1]\n",
    "    predictions_tr[toxicity] = models[toxicity].best_estimator_.predict_proba(X_train)[:, 1]\n",
    "    print(toxicity)\n",
    "    ll = log_loss(y_val[toxicity], predictions[toxicity])\n",
    "    ll_tr = log_loss(y_train[toxicity], predictions_tr[toxicity])\n",
    "    print('test log-loss: %s' % str(ll.round(3)))\n",
    "    print('train log-loss: %s' % str(ll_tr.round(3)))\n",
    "    loss = loss + ll\n",
    "    loss_tr = loss_tr + ll_tr\n",
    "    print('test confusion matrix')\n",
    "    print(confusion_matrix(y_val[toxicity], models[toxicity].best_estimator_.predict(X_val)))\n",
    "print('test mean log-loss: %s' % str(loss/6.))\n",
    "print('train mean log-loss: %s' % str(loss_tr/6.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_val_df.reset_index(drop=True))\n",
    "df['label'] = y_val['toxic'].reset_index(drop=True)\n",
    "df['pred'] = predictions['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_cloud(col):\n",
    "    text = '.. '.join(list(col))\n",
    "    wordcloud = WordCloud(max_font_size=40).generate(text)\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_cloud(df[(df.label==1) & (df.pred>0.5)].comment_text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.comment_text_clean.str.contains('hate u')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.label==0) & (df.pred>0.5)].comment_text_clean.iloc[107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.comment_text.str.contains('I promise you')]['comment_text'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = vect.transform(test['comment_text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(test.id)\n",
    "for toxicity in classes:\n",
    "    predictions[toxicity] = models[toxicity].predict_proba(feature_selector[toxicity].transform(Xtest))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.to_csv(datetime.now().strftime('%Y%m%d%H%M')+'_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
